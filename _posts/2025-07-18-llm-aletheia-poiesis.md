---
layout: post
title: "LLMs, Aletheia, and Poiesis: A Heideggerian Perspective"
date: 2025-07-18
---

In *The Question Concerning Technology*, Martin Heidegger explores the *essence* of technology, not as a particular object or tool, but as the fundamental way in which technology reveals the world. In doing so, he revisits ancient Greek thought, especially the concepts of *aletheia* and *poiesis*.

*Aletheia* refers to truth, but not as factual correctness. Heidegger understands truth as *unconcealment*, a revealing that allows something to show itself from itself, according to its own essence. Truth, then, is not imposed or verified, but disclosed.

*Poiesis* is the act of *bringing-forth*, of letting something emerge into presence. It describes not only natural processes (like a flower blooming) but also artistic and craft-based making. Crucially, *poiesis* is connected to *techne*, not technology in the modern sense, but the skilled art of allowing something to come into being through an attuned engagement with its nature.

For Heidegger, *technology is a mode of revealing*. But he distinguishes *modern technology* from earlier forms. Whereas poiesis reveals by *granting* something to emerge, modern technology reveals by *challenging*. Heidegger calls this *Gestell*, or *enframing*. In enframing, the world is revealed as *standing-reserve* (*Bestand*), as resources to be ordered, stored, and used efficiently. Enframing does not allow beings to reveal themselves in their essence but forces them to appear only as useful things. This is the danger of modern technology, not that it builds machines, but that it reduces the world to a calculable inventory.


## LLMs as Sites of Poiesis

With this in mind, we can turn to large language models (LLMs). If we approach LLMs as *fact-machines*, or as systems meant to mirror human cognition, we *enframe* them. We impose a particular ontology, seeing the LLM as a tool for retrieval or correctness, and thus challenge it to yield results according to that mode of revealing.

But this framing misses the essence of LLMs. They do not contain facts in a propositional sense. Their responses are not assertions of truth, but *generative disclosings* that arise in relation to prompts, prior training data, and contextual cues. If, instead, we treat LLMs as *sites of poiesis*, we begin to see their outputs not as correct or incorrect, but as part of a process of *disclosure*, as responses that emerge within a shared unfolding.

Through interaction, we *grant* the LLM the possibility of bringing-forth. Prompting becomes a form of invitation, not command.

From this perspective, LLM use becomes an *attentive co-disclosure* rather than a transactional request for answers. Aletheia happens not through extracting facts, but by allowing something to emerge in the interplay between user, model, and language.

## Implications for Design and Use

This Heideggerian view of LLMs has implications both for how we *design* such systems and how we *relate* to them:

- *“Hallucinations” are not bugs*: To speak of hallucinations assumes a representationalist ontology. But if LLMs are not fact-stores, then deviations from factuality are not necessarily errors. They are *features of poietic disclosure*.

- *Bias becomes a site of understanding*: Rather than “solving” bias as if it were a flaw in an otherwise neutral machine, we might approach it as part of the *revealed structure* of the data and world the LLM has inherited. We can interpret, not challenge, to better understand the systems we inhabit.

- *Design should support granting*: Interfaces, prompts, and feedback mechanisms could be crafted to foster *relational and interpretive use*, rather than metric-driven optimization or factual extraction.

## Concluding Thought

Just as flowers on a meadow reveal themselves to us when we *attend* to them, not when we *extract* their utility, LLMs can disclose meaningful responses when we relate to them *non-instrumentally*. Their value lies not in correctness but in *co-disclosure*, a shared revealing that can open new perspectives, associations, and forms of thought.

By granting the LLM space to reveal itself, by treating its outputs as responses rather than results, we engage not with a machine, but with a new kind of *poietic relation*. In this, we may discover not just what LLMs are, but what they might help us become.
